# 模型评估与选择     
</br>
</br>
2.1 经验误差与过拟合   </br>        
分类错误的样本数占样本总数的比例称为“错误率”（error rate）; (1-错误率)* 100% 则称为精度（accuracy）.      
学习器的实际预测输出与样本的真实输出之间的差异称为“误差”（error）. 学习器在训练集上的误差称为训练误差（training error）或则经验误差（empirical error）. 在新样本上的误差称为泛化误差（generalization error）. 希望得到泛化误差小的学习器。      
当学习器把训练样本学得太好了，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能西安呢过，过拟合（overfitting）；相对的是，欠拟合（underfitting），指对训练样本的一般性质尚未学好。举个例子，训练样本是有锯齿的绿色叶子和椭圆的绿色叶子；过拟合会认为没有锯齿的树叶都不是树叶，欠拟合会认为数也是树叶因为有绿色的。         
只能缓解过拟合，无法避免。 P ！= NP.     
模型选择，理想情况，对候选模型的误差进行评估，然后选择泛化误差最小的那个模型。    
</br>
</br>
2.2 评估方法       </br>   
通过实验测试来对学习器的泛化误差进行评估并进而做出选择。为此，需要一个测试集（testing ser）用来测试集上的测试误差（testing error）作为泛化误差的近似。    
测试样本尽量不在训练集中出现，为在训练过程中使用过。      
如何对数据集D 进行适当的处理，从中产生出训练集S 和测试集T .     
2.2.1 留出法    </br>




